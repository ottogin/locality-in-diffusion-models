<p align="center">
  This is the official implementation of the paper
</p>

<div id="user-content-toc" display="inline">
  <ul align="center" style="list-style: none;">
    <summary>
      <h1>Locality in Image Diffusion Models Emerges from Data Statistics</h1>
    </summary>
  </ul>

<p align="center">
  <a href="https://arxiv.org/abs/2509.09672">
    <img src="https://img.shields.io/badge/arXiv-2509.09672-b31b1b.svg?logo=arXiv">
  </a>
  <a href="https://locality.lukoianov.com">
    <img src="https://img.shields.io/badge/Project%20Page-Website-b78601.svg">
  </a>
</p>

<p align="center">
    <a class="active text-decoration-none" href="https://lukoianov.com">Artem Lukoianov</a><sup> 1</sup>,  &nbsp;
    <a class="active text-decoration-none" href="https://chenyang.co">Chenyang Yuan</a><sup> 2</sup>, &nbsp;
    <a class="active text-decoration-none" href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a><sup> 1</sup>, &nbsp;
    <a class="active text-decoration-none" href="https://www.vincentsitzmann.com">Vincent Sitzmann</a><sup> 1</sup>
</p>
<p align="center">
  <span class="author-block"><sup>1 </sup>Massachusetts Institute of Technology,</span>&nbsp;
  <span class="author-block"><sup>2 </sup>Toyota Research Institute</span>
</p>

<p align="center">
  For any questions please shoot an email to <a href="mailto:arteml@mit.edu">arteml@mit.edu</a>
</p>

## Abstract

Among generative models, diffusion models are uniquely intriguing due to the existence of a closed-form optimal minimizer of their training objective, often referred to as the optimal denoiser. However, diffusion using this optimal denoiser merely reproduces images in the training set and hence fails to capture the behavior of deep diffusion models. Recent work has attempted to characterize this gap between the optimal denoiser and deep diffusion models, proposing analytical, training-free models that can generate images that resemble those generated by a trained UNet. The best-performing method hypothesizes that shift equivariance and locality inductive biases of convolutional neural networks are the cause of the performance gap, hence incorporating these assumptions into its analytical model. In this work, we present evidence that the locality in deep diffusion models emerges as a statistical property of the image dataset, not due to the inductive bias of convolutional neural networks. Specifically, we demonstrate that an optimal parametric linear denoiser exhibits similar locality properties to the deep neural denoisers. We further show, both theoretically and experimentally, that this locality arises directly from the pixel correlations present in natural image datasets. Finally, we use these insights to craft an analytical denoiser that better matches scores predicted by a deep diffusion model than the prior expert-crafted alternative.

## Code

ðŸš§ **Code coming soon!** 

This repository will contain the official implementation of our analytical denoiser and experimental code for reproducing the results in the paper.

## Citation

If you find our project useful, please consider citing it:

```bibtex
@misc{lukoianov2025localityimagediffusionmodels,
      title={Locality in Image Diffusion Models Emerges from Data Statistics}, 
      author={Artem Lukoianov and Chenyang Yuan and Justin Solomon and Vincent Sitzmann},
      year={2025},
      eprint={2509.09672},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.09672}, 
}
```
