{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Locality in Diffusion Models â€” Playground\n",
        "\n",
        "This notebook lets you experiment with the analytical diffusion models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf, open_dict\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from local_diffusion.configuration import load_config\n",
        "from local_diffusion.data import build_dataset\n",
        "from local_diffusion.models import create_model\n",
        "from local_diffusion.models.baseline_unet import BaselineUNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Edit the YAML below to change the dataset, model, or sampling parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Auto-detect device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config from file with overrides for notebook use\n",
        "#   Model options: pca_locality, wiener, optimal, nearest_dataset \n",
        "#   Dataset options: mnist, cifar10, celeba_hq, afhq, fashion_mnist\n",
        "cfg = load_config(\"pca_locality/celeba_hq.yaml\", overrides=[\n",
        "    f\"experiment.device={device}\",\n",
        "    \"sampling.num_inference_steps=10\",\n",
        "    \"sampling.num_samples=8\",\n",
        "    \"dataset.num_workers=0\",\n",
        "])\n",
        "\n",
        "print(f\"Dataset: {cfg.dataset.name}, Model: {cfg.model.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = build_dataset(cfg.dataset)\n",
        "print(f\"Dataset: {dataset.name}, Resolution: {dataset.resolution}, Channels: {dataset.in_channels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model\n",
        "\n",
        "Create and train (load/compute Wiener filter), then sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model(\n",
        "    cfg.model.name,\n",
        "    dataset=dataset,\n",
        "    device=cfg.experiment.device,\n",
        "    num_steps=cfg.sampling.num_inference_steps,\n",
        "    params=OmegaConf.to_container(cfg.model.params),\n",
        ")\n",
        "model.train(dataset) # \"Train\" is not eaxcalty training since we are working with analytical models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample from our model\n",
        "torch.manual_seed(cfg.experiment.seed)\n",
        "generator = torch.Generator(device=cfg.experiment.device).manual_seed(cfg.experiment.seed)\n",
        "\n",
        "result = model.sample(\n",
        "    num_samples=cfg.sampling.num_samples,\n",
        "    batch_size=cfg.sampling.batch_size,\n",
        "    generator=generator,\n",
        "    return_intermediates=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Postprocess and visualize\n",
        "images_ours = dataset.postprocess(result.images)\n",
        "grid_ours = make_grid(images_ours, nrow=4, padding=2).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(grid_ours)\n",
        "plt.title(\"Analytic model\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize x0 trajectory for our model\n",
        "n_steps = len(result.trajectory_x0)\n",
        "n_samples = min(4, result.trajectory_x0[0].shape[0])\n",
        "\n",
        "fig, axes = plt.subplots(n_samples, n_steps, figsize=(2*n_steps, 2*n_samples))\n",
        "for i in range(n_samples):\n",
        "    for j, x0 in enumerate(result.trajectory_x0):\n",
        "        img = dataset.postprocess(x0[i:i+1]).squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "        if img.shape[-1] == 1:\n",
        "            img = img.squeeze(-1)\n",
        "        axes[i, j].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
        "        axes[i, j].axis(\"off\")\n",
        "        if i == 0:\n",
        "            axes[i, j].set_title(f\"t={result.timesteps[j]}\", fontsize=10)\n",
        "\n",
        "fig.suptitle(\"Our Model: x0 predictions across timesteps\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline: Trained UNet\n",
        "\n",
        "Load the pretrained UNet and sample with the same seed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline = BaselineUNet(\n",
        "    resolution=dataset.resolution,\n",
        "    device=cfg.experiment.device,\n",
        "    num_steps=cfg.sampling.num_inference_steps,\n",
        "    model_path=cfg.metrics.baseline_path,\n",
        "    dataset_name=dataset.name,\n",
        "    in_channels=dataset.in_channels,\n",
        "    out_channels=dataset.in_channels,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample from baseline with same seed\n",
        "torch.manual_seed(cfg.experiment.seed)\n",
        "generator = torch.Generator(device=cfg.experiment.device).manual_seed(cfg.experiment.seed)\n",
        "\n",
        "result_baseline = baseline.sample(\n",
        "    num_samples=cfg.sampling.num_samples,\n",
        "    batch_size=cfg.sampling.batch_size,\n",
        "    generator=generator,\n",
        "    return_intermediates=True,\n",
        ")\n",
        "\n",
        "images_baseline = dataset.postprocess(result_baseline.images)\n",
        "grid_baseline = make_grid(images_baseline, nrow=4, padding=2).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(grid_baseline)\n",
        "plt.title(\"Baseline (Trained UNet)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize x0 trajectory for baseline\n",
        "n_steps = len(result_baseline.trajectory_x0)\n",
        "n_samples = min(4, result_baseline.trajectory_x0[0].shape[0])\n",
        "\n",
        "fig, axes = plt.subplots(n_samples, n_steps, figsize=(2*n_steps, 2*n_samples))\n",
        "for i in range(n_samples):\n",
        "    for j, x0 in enumerate(result_baseline.trajectory_x0):\n",
        "        img = dataset.postprocess(x0[i:i+1]).squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "        if img.shape[-1] == 1:\n",
        "            img = img.squeeze(-1)\n",
        "        axes[i, j].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
        "        axes[i, j].axis(\"off\")\n",
        "        if i == 0:\n",
        "            axes[i, j].set_title(f\"t={result_baseline.timesteps[j]}\", fontsize=10)\n",
        "\n",
        "fig.suptitle(\"Baseline UNet: x0 predictions across timesteps\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Side-by-Side Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "axes[0].imshow(grid_ours)\n",
        "axes[0].set_title(\"Analytic model\", fontsize=14)\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(grid_baseline)\n",
        "axes[1].set_title(\"Baseline (UNet)\", fontsize=14)\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
